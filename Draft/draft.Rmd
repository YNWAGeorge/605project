---
title: "First draft"
author: "Tinghui Xu, Ouyang Xu, Bowen Tian, Yijin Guan, Yifan Du"
date: "12/3/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


Github: https://github.com/YNWAGeorge/STAT605GroupProject


# 1 Introduction


As we all know, Amazon is the online retailer with the largest variety of products in the world. It's meaningful for either customers or the business owners to know more about the reviews of the items. Our main goal is to explore which aspects are mostly mentioned. This can help sellers improve their stars. So we use CHTC/HPC to find the relationship between the high frequency words and rating stars.


# 2 Methodology


## 2.1 Description of data


Our Amazon dataset can be obtained from Kaggle(https://www.kaggle.com/cynthiarempel/amazon-us-customer-reviews-dataset). Amazon is founded in 1994 and it developed to be the largest integrated online retailer in 1997. In a period of over two decades since the first review in 1995, millions of Amazon customers have contributed more than hundred million reviews to express opinions and describe their experiences regarding products on the Amazon.com website. This makes Amazon Customer Reviews a rich source of information for academic researchers in the fields of Natural Language Processing (NLP), Information Retrieval (IR), and Machine Learning (ML), amongst others. Our dataset contains 6 sub files. Each file contains the sales records and comments of a certain category of goods in the US. Each data file has 15 columns containing variables like 'product_category', 'star_rating', and 'review_body' etc. And there are totally 22175051 reviews in our data set.


```{r, echo = F, message = F, warning = F}
library(tidytext)
library(dplyr)
library(readr)
library(tm)
library(SnowballC)
library(stringr)
library(knitr)
library(udpipe)
library(tidyr)
library(ggplot2)
udmodel <- udpipe_download_model(language = "english")
udmodel <- udpipe_load_model(file = udmodel$file_model)

#data <- read_tsv('amazon_reviews_us_Digital_Video_Download_v1_00.tsv')
#kable(data[1,1:5])
#kable(data[1,6:10])
#kable(data[1,11:15])
```

## 2.2 Data processing

First, we use a bash file named "split.sh" to split all 6 tsv files into tens of small tsv files, each 100MB. Then we run "word_freq_array.sh" to access these files to do the parallel computation for each category. Finally, "merge.sh" merges all the csv files into a combined csv file using the given category.

For example, we split the camera.tsv (1.1GB) into 11 small tsv files. After that, we run "word_freq_array_camera.sh" to launch 11 small jobs. Each job does the tokenization and lemmatization to each csv file, and then calculates the frequency of each word, returning a csv file with Column word, star_ratings, and frequency. Then, a bash file named "merge.sh" merges all these csv files about camera into one csv file. 

At last, we got 6 combined csv files for further analysis, which were done in local.

## 2.3 Text processing

In order to make our result and conclusion more precise, we do some work before we do tokenization on the customers' reviews. First we remove all of the punctuation and some html elements like *\<br/>* and *\&#34;*. Then we turn each and every letter to lower-case letter and do lemmatization, which can transform words like 'swims', 'swam', 'swimming' to 'swim'. After this we do tokenization to separate the strings into single words. At last we remove all the stop words to get our final word boxes. 

## 2.4 Computation for words frequency

We groupe our word boxes to get words frequency results. Since we split the raw data, we extracte top 2000 words in each split file and merge them into one .csv file. Then we select all the nouns from the words we get. We do these on each of the 6 sub files since they are different product categories. 
### camera
```{r, echo = F}
data_2 <- read.csv("../Data/camera.csv") %>% filter(word.stem != "br" & word.stem != "camera")
data_2$star_rating <- data_2$star_rating %>% factor
data_2$star_rating <- str_c("star_",data_2$star_rating)
kable(data_2[13:17, -1])
```

## 2.5 Word frequency v.s. Star rating plot

In 2.4, when we are getting words frequency, we keep the star rating and the product category of the reviews where certain words are split from. So we have the relationship between high frequency words and star ratings. And we can intuitively analyse some of the interesting words and based on these we can make suggestions or predictions.

```{r, echo = F}
noun <- udpipe_annotate(udmodel, 
                     unique(data_2$word.stem)) %>% 
  as.data.frame() %>% 
  select(token, upos) %>% filter(upos == "NOUN") %>% unlist

data_3 <- data_2 %>% filter(word.stem %in% noun) %>% 
  group_by(word.stem) %>%
  summarise(all_freq = sum(frequency)) 

data_4 <- data_2 %>% select(-X) %>% 
  spread(star_rating, frequency)

kable(data_4[13:17, -1])
```

# 3 Conclusion

```{r, echo = F}
word_list1 <- c("price","tripod","len","lamp","dvd","polici","refund","plugin","flicker")
data_2 <- read.csv("../Data/camera.csv") %>% filter(word.stem != "br" & word.stem != "camera")
data_2$star_rating <- data_2$star_rating %>% factor
data_2 %>%
  filter(word.stem %in% word_list1) %>% 
  ggplot()+
    geom_bar(aes(x = star_rating,y = frequency,fill = star_rating),stat = "identity")+
    facet_wrap(~word.stem,scales = "free")
```

This is our first draft and we plan to complete it in the next few days.




