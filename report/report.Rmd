---
title: "Amazon Data Analysis Report"
author: "Tinghui Xu, Ouyang Xu, Bowen Tian, Yijin Guan, Yifan Du"
date: "12/3/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


More details can be seen on our [GitHub repository](https://github.com/YNWAGeorge/605project).


# 1 Introduction


As we all know, Amazon is the online retailer with the largest variety of products in the world. It's meaningful for both customers and business owners to know more about the reviews of the items. Our main goal is to explore which aspects are mostly mentioned. This can help sellers improve their stars. Therefore, we use CHTC to find the relationship between the high-frequency words and rating stars.


# 2 Methodology


## 2.1 Description of data


Our Amazon dataset can be obtained from [Kaggle's Amazon US Customer Reviews Dataset](https://www.kaggle.com/cynthiarempel/amazon-us-customer-reviews-dataset). Amazon was founded in 1994 and it developed to be the largest integrated online retailer in 1997. In a period of over two decades since the first review in 1995, millions of Amazon customers have contributed more than a hundred million reviews to express opinions and describe their experiences regarding products on the Amazon.com website. This makes Amazon Customer Reviews a rich source of information for academic researchers in the fields of Natural Language Processing (NLP), Information Retrieval (IR), and Machine Learning (ML), amongst others. Our dataset contains 6 subfiles. Each file contains the sales records and comments of a certain category of goods in the US. Each data file has 15 columns containing variables like 'product_category', 'star_rating', and 'review_body' etc. There are 22175051 reviews in our data set.


```{r, echo = F, message = F, warning = F}
library(tidytext)
library(dplyr)
library(readr)
library(tm)
library(SnowballC)
library(stringr)
library(knitr)
library(udpipe)
library(tidyr)
library(ggplot2)
library(unikn)
udmodel <- udpipe_download_model(language = "english")
udmodel <- udpipe_load_model(file = udmodel$file_model)

#data <- read_tsv('amazon_reviews_us_Digital_Video_Download_v1_00.tsv')
#kable(data[1,1:5])
#kable(data[1,6:10])
#kable(data[1,11:15])
```

## 2.2 Data processing

We use R in CHTC to do parallel computation. We use "install_R.sh" and "interactive.sub" to download all the R packages we need and compress them to "packages.tar.gz" so that we do not need to download R packages again in future parallel jobs. 

Then we start our main procedures of parallel computation. First, we use a bash file named "split.sh" to split all 6 tsv files into 124 small tsv files, each no greater than 100MB. It also finds all the 124 small files and compiles the file names to a list named "file_list". Next, we pass the "file_list" and "packages.tar.gz" to "word_freq.sub" to launch 124 parallel jobs in 124 computer nodes.  For each job, we use "word_freq.sh" and "word_freq.R" to do the text processing and computation for word frequency, which will be elaborated in 2.4 and 2.5. Each job returns a csv file recording the frequency results. Each job takes 5-10 minutes to run and requires 5GB memory and 5GB disk space. Then, a bash file named "merge.sh" merges all the 124 returned csv files into one csv file. All the main procedures mentioned above are included in the "submit.dag" and we only need to run this dag file. Next, we will introduce what we do in each parallel job.

## 2.3 Text processing


## 2.4 Computation for word frequency

In each of the 124 split csv files, we group our word boxes and calculate frequency for each word. Then we keep 2000 words with the highest frequency in each csv file with Column "product_category", "word.stem", "star_ratings", and "frequency". Then we merge them to one csv file as we mention in 2.2. Parts of the csv file we get are as follows:   

### book
```{r, echo = F}
data_2 <- read.csv("../Data/book.csv") %>% filter(word.stem != "br" & word.stem != "book")
data_2$star_rating <- data_2$star_rating %>% factor
data_2$star_rating <- str_c("star_",data_2$star_rating)
kable(data_2[13:17, -1])
```
### camera
```{r, echo = F}
data_2 <- read.csv("../Data/camera.csv") %>% filter(word.stem != "br" & word.stem != "camera")
data_2$star_rating <- data_2$star_rating %>% factor
data_2$star_rating <- str_c("star_",data_2$star_rating)
kable(data_2[13:17, -1])
```

## 2.5 Word frequency v.s. Star rating plot

After the computation on CHTC, we can do further analysis on the merged csv file in our local computers. We keep all the nouns in the csv.  In 2.4, when we are getting frequency, we keep the star rating and the product category of the reviews where certain words are split from. Therefore, we can transform the data structure and get the relationship between high-frequency words and star ratings. Then we can intuitively analyze some of the representative words and based on these we can make suggestions or predictions. Part of the data structure after transformation is shown as follow:

```{r, echo = F}
noun <- udpipe_annotate(udmodel, 
                     unique(data_2$word.stem)) %>% 
  as.data.frame() %>% 
  select(token, upos) %>% filter(upos == "NOUN") %>% unlist

data_3 <- data_2 %>% filter(word.stem %in% noun) %>% 
  group_by(word.stem) %>%
  summarise(all_freq = sum(frequency)) 

data_4 <- data_2 %>% select(-X) %>% 
  spread(star_rating, frequency)

kable(data_4[13:17, -1])
```

We find that no all the high-frequency words are worth analyzing. Some word stems are meaningless because we cannot identify what the original words are; some words that are not clearly relevant to the product category; some words that can not provide useful information such as "book" and so on. Therefore, we will select the meaningful high frequency words. Besides the frequency, we also choose some words that appear frequently in 1 star reviews. We make the following plots to show the relationship between the  star ratings and the high frequency word stems.


```{r, echo = F}
data_2 <- read.csv("../data/book.csv") %>% filter(word.stem != "br" & word.stem != "aw" & word.stem != "book")


data_2$star_rating <- data_2$star_rating %>% factor

data_2$star_rating <- str_c("star_",data_2$star_rating)

noun <- udpipe_annotate(udmodel, 
                     unique(data_2$word.stem)) %>% 
  as.data.frame() %>% 
  select(token, upos) %>% filter(upos == "NOUN") %>% unlist

data_3 <- data_2 %>% filter(word.stem %in% noun) %>% 
  group_by(word.stem) %>%
  summarise(all_freq = sum(frequency)) 

data_4 <- data_2 %>% filter(word.stem %in% noun) %>% select(-X) %>% 
  spread(star_rating, frequency)


most_freq_word <- data_3$word.stem[order(data_3$all_freq,decreasing = T)] %>% 
  head(3)

least = data_4$word.stem[data_4$star_5<data_4$star_1] 

sift_least = least %>% head(3)

word_list1 = c("children","cover","action","adventur","insult","mislead")

data_2 <- read.csv("../data/book.csv") %>% filter(word.stem != "br" & word.stem != "aw" & word.stem != "book")
data_2$star_rating <- data_2$star_rating %>% factor
data_2 %>%
  filter(word.stem %in% word_list1) %>% 
  ggplot()+
    geom_bar(aes(x = star_rating,y = frequency,fill = star_rating),stat = "identity")+
    facet_wrap(~word.stem,scales = "free")+ggtitle("Figure 1: Books")+scale_fill_manual(values = as.character(pal_peach[1:5]))

```



```{r, echo = F}
data_2 <- read.csv("../data/camera.csv") %>% filter(word.stem != "br" & word.stem != "aw" & word.stem != "camera")


data_2$star_rating <- data_2$star_rating %>% factor

data_2$star_rating <- str_c("star_",data_2$star_rating)

noun <- udpipe_annotate(udmodel, 
                     unique(data_2$word.stem)) %>% 
  as.data.frame() %>% 
  select(token, upos) %>% filter(upos == "NOUN") %>% unlist

data_3 <- data_2 %>% filter(word.stem %in% noun) %>% 
  group_by(word.stem) %>%
  summarise(all_freq = sum(frequency)) 

data_4 <- data_2 %>% filter(word.stem %in% noun) %>% select(-X) %>% 
  spread(star_rating, frequency)


most_freq_word <- data_3$word.stem[order(data_3$all_freq,decreasing = T)] %>% 
  head(3)

least = data_4$word.stem[data_4$star_5<data_4$star_1] 

sift_least = least %>% head(3)

word_list1 = c("price","tripod","charger","lens","flicker","lesson")

data_2 <- read.csv("../data/camera.csv") %>% filter(word.stem != "br" & word.stem != "aw" & word.stem != "camera")
data_2$star_rating <- data_2$star_rating %>% factor
data_2 %>%
  filter(word.stem %in% word_list1) %>% 
  ggplot()+
    geom_bar(aes(x = star_rating,y = frequency,fill = star_rating),stat = "identity")+
    facet_wrap(~word.stem,scales = "free")+ggtitle("Figure 2: Cameras")+scale_fill_manual(values = as.character(pal_pinky[1:5]))

```



```{r, echo = F}
data_2 <- read.csv("../data/Ebook.csv") %>% filter(word.stem != "br" & word.stem != "aw" & word.stem != "Ebook")

data_2$star_rating <- data_2$star_rating %>% factor

data_2$star_rating <- str_c("star_",data_2$star_rating)

noun <- udpipe_annotate(udmodel, 
                     unique(data_2$word.stem)) %>% 
  as.data.frame() %>% 
  select(token, upos) %>% filter(upos == "NOUN") %>% unlist

data_3 <- data_2 %>% filter(word.stem %in% noun) %>% 
  group_by(word.stem) %>%
  summarise(all_freq = sum(frequency)) 

data_4 <- data_2 %>% filter(word.stem %in% noun) %>%  select(-X) %>% filter(word.stem %in% noun) %>% 
  spread(star_rating, frequency)


most_freq_word <- data_3$word.stem[order(data_3$all_freq,decreasing = T)] %>% 
  head(3)

least = data_4$word.stem[data_4$star_5<data_4$star_1] 

sift_least = least %>% head(3)

word_list1 = c("romanc","humor","fantasi","suspens","plagiar","punctuat")

data_2 <- read.csv("../data/Ebook.csv") %>% filter(word.stem != "br" & word.stem != "aw" & word.stem != "Ebook")
data_2$star_rating <- data_2$star_rating %>% factor
data_2 %>%
  filter(word.stem %in% word_list1) %>% 
  ggplot()+
    geom_bar(aes(x = star_rating,y = frequency,fill = star_rating),stat = "identity")+
    facet_wrap(~word.stem,scales = "free")+ggtitle("Figure 3:  Digital Ebook Purchase")+scale_fill_manual(values = as.character(pal_bordeaux[1:5]))
```



```{r, echo = F}
data_2 <- read.csv("../data/Electronics.csv") %>% filter(word.stem != "br" & word.stem != "aw" & word.stem != "Electronics")


data_2$star_rating <- data_2$star_rating %>% factor

data_2$star_rating <- str_c("star_",data_2$star_rating)

noun <- udpipe_annotate(udmodel, 
                     unique(data_2$word.stem)) %>% 
  as.data.frame() %>% 
  select(token, upos) %>% filter(upos == "NOUN") %>% unlist

data_3 <- data_2 %>% filter(word.stem %in% noun) %>% 
  group_by(word.stem) %>% 
  summarise(all_freq = sum(frequency)) 

data_4 <- data_2 %>% filter(word.stem %in% noun) %>%  select(-X) %>% 
  spread(star_rating, frequency)


most_freq_word <- data_3$word.stem[order(data_3$all_freq,decreasing = T)] %>% 
  head(3)

least = data_4$word.stem[data_4$star_5<data_4$star_1] 

sift_least = least %>% head(3)

word_list1 = c("cabl","headphon","speaker","price","malfunct","flicker")

data_2 <- read.csv("../data/Electronics.csv") %>% filter(word.stem != "br" & word.stem != "aw" & word.stem != "Electronics")
data_2$star_rating <- data_2$star_rating %>% factor
data_2 %>%
  filter(word.stem %in% word_list1) %>% 
  ggplot()+
    geom_bar(aes(x = star_rating,y = frequency,fill = star_rating),stat = "identity")+
    facet_wrap(~word.stem,scales = "free")+ggtitle("Figure 4: Electronics")+scale_fill_manual(values = as.character(pal_grau[1:5]))

```



```{r, echo = F}
data_2 <- read.csv("../data/Mobile.csv") %>% filter(word.stem != "br" & word.stem != "aw" & word.stem != "Mobile")


data_2$star_rating <- data_2$star_rating %>% factor

data_2$star_rating <- str_c("star_",data_2$star_rating)

noun <- udpipe_annotate(udmodel, 
                     unique(data_2$word.stem)) %>% 
  as.data.frame() %>% 
  select(token, upos) %>% filter(upos == "NOUN") %>% unlist

data_3 <- data_2 %>% filter(word.stem %in% noun) %>% 
  group_by(word.stem) %>%
  summarise(all_freq = sum(frequency)) 

data_4 <- data_2  %>% filter(word.stem %in% noun) %>% select(-X) %>% 
  spread(star_rating, frequency)


most_freq_word <- data_3$word.stem[order(data_3$all_freq,decreasing = T)] %>% 
  head(3)

least = data_4$word.stem[data_4$star_5<data_4$star_1] 

sift_least = least %>% head(3)

word_list1 = c("game","fun","kindl","kid","advertis","bandwidth")

data_2 <- read.csv("../data/Mobile.csv") %>% filter(word.stem != "br" & word.stem != "aw" & word.stem != "Mobile")
data_2$star_rating <- data_2$star_rating %>% factor
data_2 %>%
  filter(word.stem %in% word_list1) %>% 
  ggplot()+
    geom_bar(aes(x = star_rating,y = frequency,fill = star_rating),stat = "identity")+
    facet_wrap(~word.stem,scales = "free")+ggtitle("Figure 5: Mobile Apps")+scale_fill_manual(values = as.character(pal_seegruen[1:5]))
```


```{r, echo = F}
data_2 <- read.csv("../data/videodownload.csv") %>% filter(word.stem != "br" & word.stem != "aw" & word.stem != "videodownload")


data_2$star_rating <- data_2$star_rating %>% factor

data_2$star_rating <- str_c("star_",data_2$star_rating)

noun <- udpipe_annotate(udmodel, 
                     unique(data_2$word.stem)) %>% 
  as.data.frame() %>% 
  select(token, upos) %>% filter(upos == "NOUN") %>% unlist

data_3 <- data_2 %>% filter(word.stem %in% noun) %>% 
  group_by(word.stem) %>%
  summarise(all_freq = sum(frequency)) 

data_4 <- data_2 %>% filter(word.stem %in% noun) %>% select(-X) %>% 
  spread(star_rating, frequency)


most_freq_word <- data_3$word.stem[order(data_3$all_freq,decreasing = T)] %>% 
  head(3)

least = data_4$word.stem[data_4$star_5<data_4$star_1] 

sift_least = least %>% head(3)

word_list1 = c("stori","charact","episod","actor","music","clich")

data_2 <- read.csv("../data/videodownload.csv") %>% filter(word.stem != "br" & word.stem != "aw" & word.stem != "videodownload")
data_2$star_rating <- data_2$star_rating %>% factor
data_2 %>%
  filter(word.stem %in% word_list1) %>% 
  ggplot()+
    geom_bar(aes(x = star_rating,y = frequency,fill = star_rating,),stat = "identity")+
    facet_wrap(~word.stem,scales = "free")+ggtitle("Figure 6: Digital Video Download")+scale_fill_manual(values = as.character(pal_seeblau[1:5]))
```

## 2.6 Suggestions

We analyze the words in each plot and give suggestions to particular business owners respectively about what they ought to do in light of the marked words related to stars.


#### Book

- The reviewers prefer the themes like action and adventure, whose ratings are mostly 5 stars. The majority of the word "cover" are 5-star ratings. One possible explanation is that better and prettier covers of books are more likely to be mentioned in good reviews.

#### Camera

- Good quality of lens, tripods, and chargers is more likely to be mentioned in the 5-star reviews, which means customers pay more attention to these aspects.

#### Digital Ebook Purchase

- The suspense, romance, humor, and fantasy are very popular topics in 5-star reviewers. Punctuations are one of very important aspects since it appears in reviews regardless of the stars. The Ebook maker should pay more attention the punctuation problems in ebook products.

#### Electronics

- People always praise cable, headphone and speaker. We suggest the business owners to sell good products. "price" reflects that the price is reasonable. "malfunct" and "flicker" shows that people always products with problems. Business should sell products of good quality.

#### Mobile Apps

- People could have fun by using the apps. Business owners should care about the function about entertainment of apps. "kindl" reflects that customers are satisfied with kindle.Customers are always annoyed by the advertisement in the apps they bought.

#### Digital Video Download

- People always praise actor, character, episodes, music and story of the videos. We suggest the film makers to pay attention to these aspects.  People always complain about the cliche in the video. We suggest the video makers to aovid including cliche in their videos.

## 2.7 Weakness

We only calculate the frequency of words. It could only provide limited information from these reviews. We do not do further text analysis like the sentiment analysis, which enables us to see the positive and negative attitude of reviewers to each aspect. Besides, we do not connect the words with the sentences. A word may refer to different meanings in different sentences. This will reduce the precision of our analysis. 

# 3 Conclusion

In this project, we find that customers tend to focus more on certain characteristics of products from their reviews. Thus, the text analysis methods like Natural Language Processing will be of vital importance to both customers and business owners. We find out why certain words always appear in some good or bad reviews so that we can give advice to the business owners to improve their selling strategies according to consumers' behaviors and preferences. 

For our limits, we only find the high frequency words and their relationship with the star ratings. In the future, more analysis such as analyzing the sentences including the high frequency words and sentiment analysis can be done to get more precise results and give more diverse suggestions to business owners.




